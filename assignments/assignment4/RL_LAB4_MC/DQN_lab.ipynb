<<<<<<< HEAD
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Reinforcement Learning - Deep Q Network\n","If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["from custommagics import CustomMagics\n","get_ipython().register_magics(CustomMagics)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting dqn_autograde.py\n"]}],"source":["%%execwritefile dqn_autograde.py\n","import numpy as np\n","import random\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch import optim\n","from tqdm import tqdm as _tqdm\n","\n","def tqdm(*args, **kwargs):\n","    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer"]},{"cell_type":"code","execution_count":24,"metadata":{"nbgrader":{"grade":false,"grade_id":"cell-fc69f22067705372","locked":true,"schema_version":1,"solution":false}},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import sys\n","import time\n","\n","assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-fef7e20e54e6243b","locked":true,"schema_version":1,"solution":false}},"source":["## 1. Deep Q-Network (DQN)"]},{"cell_type":"code","execution_count":25,"metadata":{"nbgrader":{"grade":true,"grade_id":"cell-39519f4ab05eb2a1","locked":true,"points":0,"schema_version":1,"solution":false}},"outputs":[],"source":["import gym\n","env = gym.envs.make(\"CartPole-v1\")"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;31mType:\u001b[0m        CartPoleEnv\n","\u001b[1;31mString form:\u001b[0m <CartPoleEnv<CartPole-v1>>\n","\u001b[1;31mFile:\u001b[0m        c:\\users\\alvaro millan ruiz\\anaconda3.1\\envs\\rlcourse\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py\n","\u001b[1;31mSource:\u001b[0m     \n","\u001b[1;32mclass\u001b[0m \u001b[0mCartPoleEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;34m\"\"\"\n","    Description:\n","        A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum starts upright, and the goal is to prevent it from falling over by increasing and reducing the cart's velocity.\n","\n","    Source:\n","        This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson\n","\n","    Observation: \n","        Type: Box(4)\n","        Num     Observation                 Min         Max\n","        0       Cart Position             -4.8            4.8\n","        1       Cart Velocity             -Inf            Inf\n","        2       Pole Angle                 -24°           24°\n","        3       Pole Velocity At Tip      -Inf            Inf\n","        \n","    Actions:\n","        Type: Discrete(2)\n","        Num     Action\n","        0       Push cart to the left\n","        1       Push cart to the right\n","        \n","        Note: The amount the velocity is reduced or increased is not fixed as it depends on the angle the pole is pointing. This is because the center of gravity of the pole increases the amount of energy needed to move the cart underneath it\n","\n","    Reward:\n","        Reward is 1 for every step taken, including the termination step\n","\n","    Starting State:\n","        All observations are assigned a uniform random value between ±0.05\n","\n","    Episode Termination:\n","        Pole Angle is more than ±12°\n","        Cart Position is more than ±2.4 (center of the cart reaches the edge of the display)\n","        Episode length is greater than 200\n","        Solved Requirements\n","        Considered solved when the average reward is greater than or equal to 195.0 over 100 consecutive trials.\n","    \"\"\"\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m\n","\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;34m'render.modes'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;34m'video.frames_per_second'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m}\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m9.8\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasscart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_mass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasscart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;31m# actually half the pole's length\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.02\u001b[0m  \u001b[1;31m# seconds between state updates\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'euler'\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;31m# Angle at which to fail the episode\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m360\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2.4\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;31m# Angle limit set to 2 * theta_threshold_radians so failing observation is still within bounds\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mhigh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mhigh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseeding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%r (%s) invalid\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mforce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforce_mag\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mcostheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0msintheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mforce\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msintheta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mthetaacc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msintheta\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcostheta\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mxacc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mthetaacc\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'euler'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mx\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# semi-implicit euler\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mx\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_dot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta_dot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n","                \u001b[1;32mor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n","                \u001b[1;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \\\n","                \u001b[1;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;31m# Pole just fell!\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m                \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mscreen_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m600\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mscreen_height\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mworld_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_threshold\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscreen_width\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mworld_width\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mcarty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;31m# TOP OF CART\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mpolewidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mpolelen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mcartwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50.0\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mcartheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30.0\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0maxleoffset\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mcart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcarttrans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mcart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpolelen\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mpole\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mpole\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoletrans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxleoffset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mpole\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mpole\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpole\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_circle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mcartx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2.0\u001b[0m \u001b[1;31m# MIDDLE OF CART\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_translation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcartx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcarty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n"]}],"source":["# env is a TimeLimit wrapper around an env, so use env.env to look into the env (but otherwise you can forget about this)\n","??env.env"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# The nice thing about the CARTPOLE is that it has very nice rendering functionality (if you are on a local environment). Let's have a look at an episode\n","obs = env.reset()\n","env.render()\n","done = False\n","while not done:\n","    obs, reward, done, _ = env.step(env.action_space.sample())\n","    env.render()\n","    time.sleep(0.05)\n","env.close()  # Close the environment or you will have a lot of render screens soon"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-2d83f70e62b99520","locked":true,"schema_version":1,"solution":false}},"source":["Remember from the previous lab, that in order to optimize a policy we need to estimate the Q-values (e.g. estimate the *action* values). In the CartPole problem, our state is current position of the cart, the current velocity of the cart, the current (angular) position of the pole and the (angular) speed of the pole. As these are continuous variables, we have an infinite number of states (ignoring the fact that a digital computer can only represent finitely many states in finite memory)."]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-0b3162496f5e6cf5","locked":true,"schema_version":1,"solution":false}},"source":["### 2.1 Implement Q-Network"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-96a86bcfa1ebc84a","locked":true,"schema_version":1,"solution":false}},"source":["We will not use the tabular approach but approximate the Q-value function by a general approximator function. We will skip the linear case and directly use a two layer Neural Network. We use [PyTorch](https://pytorch.org/) to implement the network, as this will allow us to train it easily later. We can implement a model using `torch.nn.Sequential`, but with PyTorch it is actually very easy to implement the model (e.g. the forward pass) from scratch. Now implement the `QNetwork.forward` function that uses one hidden layer with ReLU activation (no output activation)."]},{"cell_type":"code","execution_count":28,"metadata":{"nbgrader":{"grade":false,"grade_id":"cell-216429a5dccf8a0e","locked":false,"schema_version":1,"solution":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to dqn_autograde.py\n"]}],"source":["%%execwritefile -a dqn_autograde.py\n","\n","class QNetwork(nn.Module):\n","    \n","    def __init__(self, num_hidden=128):\n","        nn.Module.__init__(self)\n","        self.l1 = nn.Linear(4, num_hidden)\n","        self.l2 = nn.Linear(num_hidden, 2)\n","\n","    def forward(self, x):\n","        x = self.l1(x)\n","        x = F.relu(x)\n","        x = self.l2(x)\n","        return x\n"]},{"cell_type":"code","execution_count":29,"metadata":{"nbgrader":{"grade":true,"grade_id":"cell-00ce108d640a5942","locked":true,"points":1,"schema_version":1,"solution":false}},"outputs":[],"source":["# Let's instantiate and test if it works\n","num_hidden = 128\n","torch.manual_seed(1)\n","Q_net = QNetwork(num_hidden)\n","\n","torch.manual_seed(1)\n","test_model = nn.Sequential(\n","    nn.Linear(4, num_hidden), \n","    nn.ReLU(), \n","    nn.Linear(num_hidden, 2)\n",")\n","\n","x = torch.rand(10, 4)\n","\n","# If you do not need backpropagation, wrap the computation in the torch.no_grad() context\n","# This saves time and memory, and PyTorch complaints when converting to numpy\n","with torch.no_grad():\n","    assert np.allclose(Q_net(x).numpy(), test_model(x).numpy())"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-ca77eae2e62180cf","locked":true,"schema_version":1,"solution":false}},"source":["### 2.2 Experience Replay"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-2c1d117a1a75fd69","locked":true,"schema_version":1,"solution":false}},"source":["In order to stabilize learning, we will use an experience replay to save states in and sample states from. Now implement the `push` function that adds a transition to the replay buffer, and the `sample` function that samples a (random!) batch of data, for use during training (hint: you can use the function `random.sample`). It should keep at most the maximum number of transitions."]},{"cell_type":"code","execution_count":30,"metadata":{"nbgrader":{"grade":false,"grade_id":"cell-a3cc876e51eb157f","locked":false,"schema_version":1,"solution":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to dqn_autograde.py\n"]}],"source":["%%execwritefile -a dqn_autograde.py\n","\n","class ReplayMemory:\n","    \n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","\n","    def push(self, transition):\n","        # YOUR CODE HERE\n","        if len(self.memory) > self.capacity-1:\n","            self.memory.pop(0)\n","            self.memory.append(transition)\n","        else:\n","            # If the memory is full, remove the oldest transition to make space for the new one.\n","            self.memory.append(transition)\n","\n","    def sample(self, batch_size):\n","        # YOUR CODE HERE\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["class ReplayMemory:\n","    \n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","\n","    def push(self, transition):\n","        # YOUR CODE HERE\n","        if len(self.memory) == self.capacity:\n","            self.memory.pop\n","\n","        self.memory.append(transition)\n","\n","    def sample(self, batch_size):\n","        # YOUR CODE HERE\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"]},{"cell_type":"code","execution_count":32,"metadata":{"nbgrader":{"grade":true,"grade_id":"cell-3b90135921c4da76","locked":true,"points":1,"schema_version":1,"solution":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["[(array([ 0.00813955, -0.00287877, -0.0042961 , -0.02323334]), 1, 1.0, array([ 0.00808198,  0.19230452, -0.00476077, -0.31726864]), False)]\n"]}],"source":["capacity = 10\n","memory = ReplayMemory(capacity)\n","\n","# Sample a transition\n","s = env.reset()\n","a = env.action_space.sample()\n","s_next, r, done, _ = env.step(a)\n","\n","# Push a transition\n","memory.push((s, a, r, s_next, done))\n","\n","# Sample a batch size of 1\n","print(memory.sample(1))"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-88f67e3c051da6a9","locked":true,"schema_version":1,"solution":false}},"source":["### 2.3 $\\epsilon$psilon greedy policy"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-aa3c7d1b3000f697","locked":true,"schema_version":1,"solution":false}},"source":["In order to learn a good policy, we need to explore quite a bit initially. As we start to learn a good policy, we want to decrease the exploration. As the amount of exploration using an $\\epsilon$-greedy policy is controlled by $\\epsilon$, we can define an 'exploration scheme' by writing $\\epsilon$ as a function of time. There are many possible schemes, but we will use a simple one: we will start with only exploring (so taking random actions) at iteration 0, and then in 1000 iterations linearly anneal $\\epsilon$ such that after 1000 iterations we take random (exploration) actions with 5\\% probability (forever, as you never know if the environment will change)."]},{"cell_type":"code","execution_count":33,"metadata":{"nbgrader":{"grade":false,"grade_id":"cell-5789e7a792108576","locked":false,"schema_version":1,"solution":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to dqn_autograde.py\n"]}],"source":["%%execwritefile -a dqn_autograde.py\n","\n","def get_epsilon(it):\n","    # YOUR CODE HERE\n","    if it < 1000:\n","        epsilon = 1.0 - (0.95 * it / 1000.0)\n","    else:\n","        epsilon = 0.05\n","\n","    epsilon = max(epsilon, 0.05)\n","    return epsilon"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["def get_epsilon(it):\n","    # YOUR CODE HERE\n","    anneal = 1000\n","    epsilon_i = 1\n","    epsilon_f = 0.05\n","    \n","    epsilon = max(epsilon_i - (it/anneal) * (epsilon_i - epsilon_f), epsilon_f)\n","    \n","    return epsilon"]},{"cell_type":"code","execution_count":35,"metadata":{"nbgrader":{"grade":true,"grade_id":"cell-40e66db45e742b2e","locked":true,"points":1,"schema_version":1,"solution":false}},"outputs":[{"data":{"text/plain":["[<matplotlib.lines.Line2D at 0x25381118d08>]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# So what's an easy way to check?\n","plt.plot([get_epsilon(it) for it in range(5000)])"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-a8b604c9998c6c3b","locked":true,"schema_version":1,"solution":false}},"source":["Now write a function of *EpsilonGreedyPolicy* class. This function takes a state and uses the Q-network to select an ($\\epsilon$-greedy) action. It should return a random action with probability epsilon. Note, you do not need to backpropagate through the model computations, so use `with torch.no_grad():` (see above for example). Note that to convert a PyTorch tensor with only 1 element (0 dimensional) to a simple python scalar (int or float), you can use the '.item()' function."]},{"cell_type":"code","execution_count":36,"metadata":{"nbgrader":{"grade":false,"grade_id":"cell-878ad3a637cfb51c","locked":false,"schema_version":1,"solution":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to dqn_autograde.py\n"]}],"source":["%%execwritefile -a dqn_autograde.py\n","\n","class EpsilonGreedyPolicy(object):\n","    \"\"\"\n","    A simple epsilon greedy policy.\n","    \"\"\"\n","    def __init__(self, Q, epsilon):\n","        self.Q = Q\n","        self.epsilon = epsilon\n","    \n","    def sample_action(self, obs):\n","        \"\"\"\n","        This method takes a state as input and returns an action sampled from this policy.  \n","\n","        Args:\n","            obs: current state\n","\n","        Returns:\n","            An action (int).\n","        \"\"\"\n","        # YOUR CODE HERE\n","        with torch.no_grad():\n","            obs = torch.tensor(obs, dtype=torch.float32)\n","            # Calculate Q-values for all actions\n","            q_values = self.Q(obs)\n","            # Choose an action using epsilon-greedy strategy\n","            if torch.rand(1).item() < self.epsilon:\n","                # Randomly select an action with probability epsilon\n","                action = torch.randint(0, q_values.shape[-1], (1,)).item()\n","            else:\n","                # Choose the action with the highest Q-value with probability (1 - epsilon)\n","                action = q_values.argmax().item()\n","            return action\n","        \n","    def set_epsilon(self, epsilon):\n","        self.epsilon = epsilon"]},{"cell_type":"code","execution_count":37,"metadata":{"nbgrader":{"grade":true,"grade_id":"cell-e895338d56bee477","locked":true,"points":1,"schema_version":1,"solution":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n"]}],"source":["s = env.reset()\n","epg = EpsilonGreedyPolicy(Q_net, 0.05)\n","a = epg.sample_action(s)\n","assert not torch.is_tensor(a)\n","print (a)"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-ec5e94e0b03f8aec","locked":true,"schema_version":1,"solution":false}},"source":["### 2.4 Training function"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-d1a12cc97386fe56","locked":true,"schema_version":1,"solution":false}},"source":["Now we will implement the function 'train' that samples a batch from the memory and performs a gradient step using some convenient PyTorch functionality. However, you still need to compute the Q-values for the (state, action) pairs in the experience, as well as their target (e.g. the value they should move towards). What is the target for a Q-learning update? What should be the target if `next_state` is terminal (e.g. `done`)?\n","\n","For computing the Q-values for the actions, note that the model returns all action values where you are only interested in a single action value. Because of the batch dimension, you can't use simple indexing, but you may want to have a look at [torch.gather](https://pytorch.org/docs/stable/torch.html?highlight=gather#torch.gather) or use [advanced indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html) (numpy tutorial but works mostly the same in PyTorch). Note, you should NOT modify the function train. You can view the size of a tensor `x` with `x.size()` (similar to `x.shape` in numpy)."]},{"cell_type":"code","execution_count":38,"metadata":{"nbgrader":{"grade":false,"grade_id":"cell-6c45485324b40081","locked":false,"schema_version":1,"solution":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to dqn_autograde.py\n"]}],"source":["%%execwritefile -a dqn_autograde.py\n","\n","def compute_q_vals(Q, states, actions):\n","    \"\"\"\n","    This method returns Q values for given state action pairs.\n","    \n","    Args:\n","        Q: Q-net\n","        states: a tensor of states. Shape: batch_size x obs_dim\n","        actions: a tensor of actions. Shape: Shape: batch_size x 1\n","\n","    Returns:\n","        A torch tensor filled with Q values. Shape: batch_size x 1.\n","    \"\"\"\n","    # YOUR CODE HERE\n","    #all_q_values = Q(states)\n","    #if actions is not None:\n","        # Convert the actions tensor to a list of indices\n","        #action_indices = actions.squeeze().tolist()\n","        #print(range(len(action_indices)))\n","        # Create a list to store the selected Q-values\n","        #q_values = []\n","        \n","        # Index the Q-values tensor manually\n","        #for i in range(len(action_indices)):\n","            #q_value = all_q_values[i][action_indices[i]]\n","            #q_values.append(q_value)\n","        \n","        # Convert the list of Q-values to a tensor and reshape it\n","        #Q_values = torch.tensor(q_values).reshape(-1, 1)\n","    #else:\n","        # If actions is None, take the maximum Q-value from all_q_values\n","       #Q_values = all_q_values.max(dim=1, keepdim=True)[0]\n","    q_values_all_actions = Q(states)\n","    q_vals = torch.gather(q_values_all_actions, dim=1, index=actions)\n","    return q_vals\n","\n","    \n","def compute_targets(Q, rewards, next_states, dones, discount_factor):\n","    \"\"\"\n","    This method returns targets (values towards which Q-values should move).\n","    \n","    Args:\n","        Q: Q-net\n","        rewards: a tensor of rewards. Shape: Shape: batch_size x 1\n","        next_states: a tensor of states. Shape: batch_size x obs_dim\n","        dones: a tensor of boolean done flags (indicates if next_state is terminal) Shape: batch_size x 1\n","        discount_factor: discount\n","    Returns:\n","        A torch tensor filled with target values. Shape: batch_size x 1.\n","    \"\"\"\n","    with torch.no_grad():\n","        next_q_values = Q(next_states)\n","        max_next_q_values = next_q_values.max(dim=1, keepdim=True)[0]\n","        #targets = rewards + (1 - dones.float()) * discount_factor * Q_vals\n","        targets = rewards + discount_factor * max_next_q_values * (1 - dones.float())\n","    return targets\n","\n","def train(Q, memory, optimizer, batch_size, discount_factor):\n","    # DO NOT MODIFY THIS FUNCTION\n","    \n","    # don't learn without some decent experience\n","    if len(memory) < batch_size:\n","        return None\n","\n","    # random transition batch is taken from experience replay memory\n","    transitions = memory.sample(batch_size)\n","    \n","    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n","    state, action, reward, next_state, done = zip(*transitions)\n","    \n","    # convert to PyTorch and define types\n","    state = torch.tensor(state, dtype=torch.float)\n","    action = torch.tensor(action, dtype=torch.int64)[:, None]  # Need 64 bit to use them as index\n","    next_state = torch.tensor(next_state, dtype=torch.float)\n","    reward = torch.tensor(reward, dtype=torch.float)[:, None]\n","    done = torch.tensor(done, dtype=torch.uint8)[:, None]  # Boolean\n","    \n","    # compute the q value\n","    q_val = compute_q_vals(Q, state, action)\n","    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n","        target = compute_targets(Q, reward, next_state, done, discount_factor)\n","    \n","    # loss is measured from error between current and newly expected Q values\n","    loss = F.smooth_l1_loss(q_val, target)\n","\n","    # backpropagation of loss to Neural Network (PyTorch magic)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    return loss.item() "]},{"cell_type":"code","execution_count":39,"metadata":{"nbgrader":{"grade":true,"grade_id":"cell-b060b822eec4282f","locked":true,"points":2,"schema_version":1,"solution":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["0.5591822266578674\n"]}],"source":["# You may want to test your functions individually, but after you do so lets see if the method train works.\n","batch_size = 64\n","discount_factor = 0.8\n","learn_rate = 1e-3\n","# Simple gradient descent may take long, so we will use Adam\n","optimizer = optim.Adam(Q_net.parameters(), learn_rate)\n","\n","# We need a larger memory, fill with dummy data\n","transition = memory.sample(1)[0]\n","memory = ReplayMemory(10 * batch_size)\n","for i in range(batch_size):\n","    memory.push(transition)\n","\n","# Now let's see if it works\n","loss = train(Q_net, memory, optimizer, batch_size, discount_factor)\n","\n","print(loss)"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-3eafd0ab49103f3b","locked":true,"schema_version":1,"solution":false}},"source":["### 2.5 Put it all together"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-36b8a04b393d8104","locked":true,"schema_version":1,"solution":false}},"source":["Now that you have implemented the training step, you should be able to put everything together. Implement the function `run_episodes` that runs a number of episodes of DQN training. It should return the durations (e.g. number of steps) of each episode. Note: we pass the train function as an argument such that we can swap it for a different training step later."]},{"cell_type":"code","execution_count":40,"metadata":{"nbgrader":{"grade":false,"grade_id":"cell-540a7d50ecc1d046","locked":false,"schema_version":1,"solution":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to dqn_autograde.py\n"]}],"source":["%%execwritefile -a dqn_autograde.py\n","\n","def run_episodes(train, Q, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate):\n","    \n","    optimizer = optim.Adam(Q.parameters(), learn_rate)\n","    \n","    global_steps = 0  # Count the steps (do not reset at episode start, to compute epsilon)\n","    episode_durations = []  \n","    for i in range(num_episodes):\n","        s = env.reset()\n","        \n","        steps = 0\n","        while True:\n","            a = policy.sample_action(s)\n","            # Store this transition in memory:\n","            s_prime, r, done, _ = env.step(a)\n","            memory.push((s, a, r, s_prime, done))\n","            s = s_prime\n","            \n","            loss = train(Q, memory, optimizer, batch_size, discount_factor)\n","            #s = s_prime\n","            steps += 1\n","            global_steps += 1\n","            \n","            # Update epsilon\n","            policy.set_epsilon(get_epsilon(global_steps))\n","            \n","            if done:\n","                if i % 10 == 0:\n","                    print(\"{2} Episode {0} finished after {1} steps\"\n","                          .format(i, steps, '\\033[92m' if steps >= 195 else '\\033[99m'))\n","                    print(\"epsilon: \", policy.epsilon)\n","                episode_durations.append(steps)\n","                #plot_durations()\n","                break\n","    #example how to do it in TD\n","     #while not done:\n","\n","            #a = policy.sample_action(s)\n","\n","            #state_prime, r, done, _ = env.step(a)\n","\n","            #next_action = policy.sample_action(state_prime)\n","\n","            #Q_max = np.max(Q[state_prime])\n","\n","            #Q[s, a] += alpha * (r + discount_factor * Q_max -  Q[s, a])\n","\n","            #s = state_prime\n","            \n","            #i += 1\n","            #R += r\n","\n","    #return episode_durations"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[99m Episode 0 finished after 21 steps\n","epsilon:  0.98005\n","\u001b[99m Episode 10 finished after 11 steps\n","epsilon:  0.82615\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[99m Episode 20 finished after 10 steps\n","epsilon:  0.677\n","\u001b[99m Episode 30 finished after 35 steps\n","epsilon:  0.4347500000000001\n","\u001b[99m Episode 40 finished after 31 steps\n","epsilon:  0.06805000000000005\n","\u001b[99m Episode 50 finished after 47 steps\n","epsilon:  0.05\n","\u001b[99m Episode 60 finished after 81 steps\n","epsilon:  0.05\n","\u001b[99m Episode 70 finished after 122 steps\n","epsilon:  0.05\n","\u001b[99m Episode 80 finished after 134 steps\n","epsilon:  0.05\n","\u001b[99m Episode 90 finished after 148 steps\n","epsilon:  0.05\n"]}],"source":["# Let's run it!\n","num_episodes = 100\n","batch_size = 64\n","discount_factor = 0.8\n","learn_rate = 1e-3\n","memory = ReplayMemory(10000)\n","num_hidden = 128\n","seed = 42  # This is not randomly chosen\n","\n","# We will seed the algorithm (before initializing QNetwork!) for reproducibility\n","random.seed(seed)\n","torch.manual_seed(seed)\n","env.seed(seed)\n","\n","Q_net = QNetwork(num_hidden)\n","policy = EpsilonGreedyPolicy(Q_net, 0.05)\n","episode_durations = run_episodes(train, Q_net, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate)"]},{"cell_type":"code","execution_count":44,"metadata":{"nbgrader":{"grade":true,"grade_id":"cell-928ecc11ed5c43d8","locked":true,"points":2,"schema_version":1,"solution":false}},"outputs":[{"ename":"TypeError","evalue":"unsupported operand type(s) for +: 'int' and 'NoneType'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Alvaro Millan Ruiz\\Anaconda3.1\\envs\\rlcourse\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'NoneType'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17856\\801642440.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcumsum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmooth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode_durations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Episode durations per episode'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17856\\801642440.py\u001b[0m in \u001b[0;36msmooth\u001b[1;34m(x, N)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# And see the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msmooth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcumsum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcumsum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcumsum\u001b[1;34m(*args, **kwargs)\u001b[0m\n","\u001b[1;32mc:\\Users\\Alvaro Millan Ruiz\\Anaconda3.1\\envs\\rlcourse\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mcumsum\u001b[1;34m(a, axis, dtype, out)\u001b[0m\n\u001b[0;32m   2530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2531\u001b[0m     \"\"\"\n\u001b[1;32m-> 2532\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cumsum'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\Alvaro Millan Ruiz\\Anaconda3.1\\envs\\rlcourse\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# Call _wrapit from within the except clause to ensure a potential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m# exception has a traceback chain.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\Alvaro Millan Ruiz\\Anaconda3.1\\envs\\rlcourse\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'NoneType'"]}],"source":["# And see the results\n","def smooth(x, N):\n","    cumsum = np.cumsum(np.insert(x, 0, 0)) \n","    return (cumsum[N:] - cumsum[:-N]) / float(N)\n","\n","plt.plot(smooth(episode_durations, 10))\n","plt.title('Episode durations per episode')"]},{"cell_type":"markdown","metadata":{},"source":["If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"]}],"metadata":{"celltoolbar":"Create Assignment","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":2}
=======
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Reinforcement Learning - Deep Q Network\n","If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from custommagics import CustomMagics\n","get_ipython().register_magics(CustomMagics)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting dqn_autograde.py\n"]}],"source":["%%execwritefile dqn_autograde.py\n","import numpy as np\n","import random\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch import optim\n","from tqdm import tqdm as _tqdm\n","\n","def tqdm(*args, **kwargs):\n","    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer"]},{"cell_type":"code","execution_count":3,"metadata":{"nbgrader":{"grade":false,"grade_id":"cell-fc69f22067705372","locked":true,"schema_version":1,"solution":false}},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import sys\n","import time\n","\n","assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-fef7e20e54e6243b","locked":true,"schema_version":1,"solution":false}},"source":["## 1. Deep Q-Network (DQN)"]},{"cell_type":"code","execution_count":4,"metadata":{"nbgrader":{"grade":true,"grade_id":"cell-39519f4ab05eb2a1","locked":true,"points":0,"schema_version":1,"solution":false}},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\hoiho\\.conda\\envs\\rlcourse\\lib\\site-packages\\gym\\envs\\registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n","  result = entry_point.load(False)\n"]}],"source":["import gym\n","env = gym.envs.make(\"CartPole-v1\")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;31mType:\u001b[0m        CartPoleEnv\n","\u001b[1;31mString form:\u001b[0m <CartPoleEnv<CartPole-v1>>\n","\u001b[1;31mFile:\u001b[0m        c:\\users\\hoiho\\.conda\\envs\\rlcourse\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py\n","\u001b[1;31mSource:\u001b[0m     \n","\u001b[1;32mclass\u001b[0m \u001b[0mCartPoleEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;34m\"\"\"\n","    Description:\n","        A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum starts upright, and the goal is to prevent it from falling over by increasing and reducing the cart's velocity.\n","\n","    Source:\n","        This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson\n","\n","    Observation: \n","        Type: Box(4)\n","        Num     Observation                 Min         Max\n","        0       Cart Position             -4.8            4.8\n","        1       Cart Velocity             -Inf            Inf\n","        2       Pole Angle                 -24°           24°\n","        3       Pole Velocity At Tip      -Inf            Inf\n","        \n","    Actions:\n","        Type: Discrete(2)\n","        Num     Action\n","        0       Push cart to the left\n","        1       Push cart to the right\n","        \n","        Note: The amount the velocity is reduced or increased is not fixed as it depends on the angle the pole is pointing. This is because the center of gravity of the pole increases the amount of energy needed to move the cart underneath it\n","\n","    Reward:\n","        Reward is 1 for every step taken, including the termination step\n","\n","    Starting State:\n","        All observations are assigned a uniform random value between ±0.05\n","\n","    Episode Termination:\n","        Pole Angle is more than ±12°\n","        Cart Position is more than ±2.4 (center of the cart reaches the edge of the display)\n","        Episode length is greater than 200\n","        Solved Requirements\n","        Considered solved when the average reward is greater than or equal to 195.0 over 100 consecutive trials.\n","    \"\"\"\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m\n","\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;34m'render.modes'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;34m'video.frames_per_second'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m}\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m9.8\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasscart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_mass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasscart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;31m# actually half the pole's length\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.02\u001b[0m  \u001b[1;31m# seconds between state updates\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'euler'\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;31m# Angle at which to fail the episode\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m360\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2.4\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;31m# Angle limit set to 2 * theta_threshold_radians so failing observation is still within bounds\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mhigh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mhigh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseeding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%r (%s) invalid\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mforce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforce_mag\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mcostheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0msintheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mforce\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msintheta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mthetaacc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msintheta\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcostheta\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mxacc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mthetaacc\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'euler'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mx\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# semi-implicit euler\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mx\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_dot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta_dot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n","                \u001b[1;32mor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n","                \u001b[1;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \\\n","                \u001b[1;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;31m# Pole just fell!\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m                \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mscreen_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m600\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mscreen_height\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mworld_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_threshold\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscreen_width\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mworld_width\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mcarty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;31m# TOP OF CART\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mpolewidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mpolelen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mcartwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50.0\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mcartheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30.0\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0maxleoffset\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mcart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcarttrans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mcart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpolelen\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mpole\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mpole\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoletrans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxleoffset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mpole\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mpole\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpole\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_circle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mcartx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2.0\u001b[0m \u001b[1;31m# MIDDLE OF CART\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_translation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcartx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcarty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n"]}],"source":["# env is a TimeLimit wrapper around an env, so use env.env to look into the env (but otherwise you can forget about this)\n","??env.env"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# The nice thing about the CARTPOLE is that it has very nice rendering functionality (if you are on a local environment). Let's have a look at an episode\n","obs = env.reset()\n","env.render()\n","done = False\n","while not done:\n","    obs, reward, done, _ = env.step(env.action_space.sample())\n","    env.render()\n","    time.sleep(0.05)\n","env.close()  # Close the environment or you will have a lot of render screens soon"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-2d83f70e62b99520","locked":true,"schema_version":1,"solution":false}},"source":["Remember from the previous lab, that in order to optimize a policy we need to estimate the Q-values (e.g. estimate the *action* values). In the CartPole problem, our state is current position of the cart, the current velocity of the cart, the current (angular) position of the pole and the (angular) speed of the pole. As these are continuous variables, we have an infinite number of states (ignoring the fact that a digital computer can only represent finitely many states in finite memory)."]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-0b3162496f5e6cf5","locked":true,"schema_version":1,"solution":false}},"source":["### 2.1 Implement Q-Network"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-96a86bcfa1ebc84a","locked":true,"schema_version":1,"solution":false}},"source":["We will not use the tabular approach but approximate the Q-value function by a general approximator function. We will skip the linear case and directly use a two layer Neural Network. We use [PyTorch](https://pytorch.org/) to implement the network, as this will allow us to train it easily later. We can implement a model using `torch.nn.Sequential`, but with PyTorch it is actually very easy to implement the model (e.g. the forward pass) from scratch. Now implement the `QNetwork.forward` function that uses one hidden layer with ReLU activation (no output activation)."]},{"cell_type":"code","execution_count":7,"metadata":{"nbgrader":{"grade":false,"grade_id":"cell-216429a5dccf8a0e","locked":false,"schema_version":1,"solution":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to dqn_autograde.py\n"]}],"source":["%%execwritefile -a dqn_autograde.py\n","\n","class QNetwork(nn.Module):\n","    \n","    def __init__(self, num_hidden=128):\n","        nn.Module.__init__(self)\n","        self.l1 = nn.Linear(4, num_hidden)\n","        self.l2 = nn.Linear(num_hidden, 2)\n","\n","    def forward(self, x):\n","        x = self.l1(x)\n","        x = F.relu(x)\n","        x = self.l2(x)\n","        return x\n"]},{"cell_type":"code","execution_count":8,"metadata":{"nbgrader":{"grade":true,"grade_id":"cell-00ce108d640a5942","locked":true,"points":1,"schema_version":1,"solution":false}},"outputs":[],"source":["# Let's instantiate and test if it works\n","num_hidden = 128\n","torch.manual_seed(1)\n","Q_net = QNetwork(num_hidden)\n","\n","torch.manual_seed(1)\n","test_model = nn.Sequential(\n","    nn.Linear(4, num_hidden), \n","    nn.ReLU(), \n","    nn.Linear(num_hidden, 2)\n",")\n","\n","x = torch.rand(10, 4)\n","\n","# If you do not need backpropagation, wrap the computation in the torch.no_grad() context\n","# This saves time and memory, and PyTorch complaints when converting to numpy\n","with torch.no_grad():\n","    assert np.allclose(Q_net(x).numpy(), test_model(x).numpy())"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-ca77eae2e62180cf","locked":true,"schema_version":1,"solution":false}},"source":["### 2.2 Experience Replay"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-2c1d117a1a75fd69","locked":true,"schema_version":1,"solution":false}},"source":["In order to stabilize learning, we will use an experience replay to save states in and sample states from. Now implement the `push` function that adds a transition to the replay buffer, and the `sample` function that samples a (random!) batch of data, for use during training (hint: you can use the function `random.sample`). It should keep at most the maximum number of transitions."]},{"cell_type":"code","execution_count":9,"metadata":{"nbgrader":{"grade":false,"grade_id":"cell-a3cc876e51eb157f","locked":false,"schema_version":1,"solution":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to dqn_autograde.py\n"]}],"source":["%%execwritefile -a dqn_autograde.py\n","\n","class ReplayMemory:\n","    \n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","\n","    def push(self, transition):\n","        # YOUR CODE HERE\n","        if len(self.memory) == self.capacity:\n","            self.memory.pop(0)\n","            \n","        self.memory.append(transition)\n","\n","    def sample(self, batch_size):\n","        # YOUR CODE HERE\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["class ReplayMemory:\n","    \n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","\n","    def push(self, transition):\n","        # YOUR CODE HERE\n","        if len(self.memory) == self.capacity:\n","            self.memory.pop\n","\n","        self.memory.append(transition)\n","\n","    def sample(self, batch_size):\n","        # YOUR CODE HERE\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"]},{"cell_type":"code","execution_count":11,"metadata":{"nbgrader":{"grade":true,"grade_id":"cell-3b90135921c4da76","locked":true,"points":1,"schema_version":1,"solution":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["[(array([ 0.03858562, -0.04311131, -0.03981317,  0.01461207]), 0, 1.0, array([ 0.03772339, -0.23764035, -0.03952093,  0.29447241]), False)]\n"]}],"source":["capacity = 10\n","memory = ReplayMemory(capacity)\n","\n","# Sample a transition\n","s = env.reset()\n","a = env.action_space.sample()\n","s_next, r, done, _ = env.step(a)\n","\n","# Push a transition\n","memory.push((s, a, r, s_next, done))\n","\n","# Sample a batch size of 1\n","print(memory.sample(1))"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-88f67e3c051da6a9","locked":true,"schema_version":1,"solution":false}},"source":["### 2.3 $\\epsilon$psilon greedy policy"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-aa3c7d1b3000f697","locked":true,"schema_version":1,"solution":false}},"source":["In order to learn a good policy, we need to explore quite a bit initially. As we start to learn a good policy, we want to decrease the exploration. As the amount of exploration using an $\\epsilon$-greedy policy is controlled by $\\epsilon$, we can define an 'exploration scheme' by writing $\\epsilon$ as a function of time. There are many possible schemes, but we will use a simple one: we will start with only exploring (so taking random actions) at iteration 0, and then in 1000 iterations linearly anneal $\\epsilon$ such that after 1000 iterations we take random (exploration) actions with 5\\% probability (forever, as you never know if the environment will change)."]},{"cell_type":"code","execution_count":12,"metadata":{"nbgrader":{"grade":false,"grade_id":"cell-5789e7a792108576","locked":false,"schema_version":1,"solution":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to dqn_autograde.py\n"]}],"source":["%%execwritefile -a dqn_autograde.py\n","\n","def get_epsilon(it):\n","    # YOUR CODE HERE\n","    if it < 1000:\n","        epsilon = 1.0 - (0.95 * it / 1000.0)\n","    else:\n","        epsilon = 0.05\n","\n","    epsilon = max(epsilon, 0.05)\n","    return epsilon"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def get_epsilon(it):\n","    # YOUR CODE HERE\n","    anneal = 1000\n","    epsilon_i = 1\n","    epsilon_f = 0.05\n","    \n","    epsilon = max(epsilon_i - (it/anneal) * (epsilon_i - epsilon_f), epsilon_f)\n","    \n","    return epsilon"]},{"cell_type":"code","execution_count":14,"metadata":{"nbgrader":{"grade":true,"grade_id":"cell-40e66db45e742b2e","locked":true,"points":1,"schema_version":1,"solution":false}},"outputs":[{"data":{"text/plain":["[<matplotlib.lines.Line2D at 0x1a944cc4148>]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# So what's an easy way to check?\n","plt.plot([get_epsilon(it) for it in range(5000)])"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-a8b604c9998c6c3b","locked":true,"schema_version":1,"solution":false}},"source":["Now write a function of *EpsilonGreedyPolicy* class. This function takes a state and uses the Q-network to select an ($\\epsilon$-greedy) action. It should return a random action with probability epsilon. Note, you do not need to backpropagate through the model computations, so use `with torch.no_grad():` (see above for example). Note that to convert a PyTorch tensor with only 1 element (0 dimensional) to a simple python scalar (int or float), you can use the '.item()' function."]},{"cell_type":"code","execution_count":15,"metadata":{"nbgrader":{"grade":false,"grade_id":"cell-878ad3a637cfb51c","locked":false,"schema_version":1,"solution":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to dqn_autograde.py\n"]}],"source":["%%execwritefile -a dqn_autograde.py\n","\n","class EpsilonGreedyPolicy(object):\n","    \"\"\"\n","    A simple epsilon greedy policy.\n","    \"\"\"\n","    def __init__(self, Q, epsilon):\n","        self.Q = Q\n","        self.epsilon = epsilon\n","    \n","    def sample_action(self, obs):\n","        \"\"\"\n","        This method takes a state as input and returns an action sampled from this policy.  \n","\n","        Args:\n","            obs: current state\n","\n","        Returns:\n","            An action (int).\n","        \"\"\"\n","        # YOUR CODE HERE\n","        with torch.no_grad():\n","            obs = torch.tensor(obs, dtype=torch.float32)\n","            # Calculate Q-values for all actions\n","            q_values = self.Q(obs)\n","            # Choose an action using epsilon-greedy strategy\n","            if torch.rand(1).item() < self.epsilon:\n","                # Randomly select an action with probability epsilon\n","                return torch.randint(0, q_values.shape[-1], (1,)).item()\n","            \n","            return q_values.argmax().item()\n","        \n","    def set_epsilon(self, epsilon):\n","        self.epsilon = epsilon"]},{"cell_type":"code","execution_count":16,"metadata":{"nbgrader":{"grade":true,"grade_id":"cell-e895338d56bee477","locked":true,"points":1,"schema_version":1,"solution":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n"]}],"source":["s = env.reset()\n","epg = EpsilonGreedyPolicy(Q_net, 0.05)\n","a = epg.sample_action(s)\n","assert not torch.is_tensor(a)\n","print (a)"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-ec5e94e0b03f8aec","locked":true,"schema_version":1,"solution":false}},"source":["### 2.4 Training function"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-d1a12cc97386fe56","locked":true,"schema_version":1,"solution":false}},"source":["Now we will implement the function 'train' that samples a batch from the memory and performs a gradient step using some convenient PyTorch functionality. However, you still need to compute the Q-values for the (state, action) pairs in the experience, as well as their target (e.g. the value they should move towards). What is the target for a Q-learning update? What should be the target if `next_state` is terminal (e.g. `done`)?\n","\n","For computing the Q-values for the actions, note that the model returns all action values where you are only interested in a single action value. Because of the batch dimension, you can't use simple indexing, but you may want to have a look at [torch.gather](https://pytorch.org/docs/stable/torch.html?highlight=gather#torch.gather) or use [advanced indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html) (numpy tutorial but works mostly the same in PyTorch). Note, you should NOT modify the function train. You can view the size of a tensor `x` with `x.size()` (similar to `x.shape` in numpy)."]},{"cell_type":"code","execution_count":17,"metadata":{"nbgrader":{"grade":false,"grade_id":"cell-6c45485324b40081","locked":false,"schema_version":1,"solution":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to dqn_autograde.py\n"]}],"source":["%%execwritefile -a dqn_autograde.py\n","\n","def compute_q_vals(Q, states, actions):\n","    \"\"\"\n","    This method returns Q values for given state action pairs.\n","    \n","    Args:\n","        Q: Q-net\n","        states: a tensor of states. Shape: batch_size x obs_dim\n","        actions: a tensor of actions. Shape: Shape: batch_size x 1\n","\n","    Returns:\n","        A torch tensor filled with Q values. Shape: batch_size x 1.\n","    \"\"\"\n","    # YOUR CODE HERE\n","    q_values_all_actions = Q(states)\n","    q_vals = torch.gather(q_values_all_actions, dim=1, index=actions)\n","    return q_vals\n","\n","    \n","def compute_targets(Q, rewards, next_states, dones, discount_factor):\n","    \"\"\"\n","    This method returns targets (values towards which Q-values should move).\n","    \n","    Args:\n","        Q: Q-net\n","        rewards: a tensor of rewards. Shape: Shape: batch_size x 1\n","        next_states: a tensor of states. Shape: batch_size x obs_dim\n","        dones: a tensor of boolean done flags (indicates if next_state is terminal) Shape: batch_size x 1\n","        discount_factor: discount\n","    Returns:\n","        A torch tensor filled with target values. Shape: batch_size x 1.\n","    \"\"\"\n","    with torch.no_grad():\n","        next_q_values = Q(next_states)\n","        max_next_q_values = next_q_values.max(dim=1, keepdim=True)[0]\n","        targets = rewards + discount_factor * max_next_q_values * (1 - dones.float())\n","        \n","    return targets\n","\n","def train(Q, memory, optimizer, batch_size, discount_factor):\n","    # DO NOT MODIFY THIS FUNCTION\n","    \n","    # don't learn without some decent experience\n","    if len(memory) < batch_size:\n","        return None\n","\n","    # random transition batch is taken from experience replay memory\n","    transitions = memory.sample(batch_size)\n","    \n","    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n","    state, action, reward, next_state, done = zip(*transitions)\n","    \n","    # convert to PyTorch and define types\n","    state = torch.tensor(state, dtype=torch.float)\n","    action = torch.tensor(action, dtype=torch.int64)[:, None]  # Need 64 bit to use them as index\n","    next_state = torch.tensor(next_state, dtype=torch.float)\n","    reward = torch.tensor(reward, dtype=torch.float)[:, None]\n","    done = torch.tensor(done, dtype=torch.uint8)[:, None]  # Boolean\n","    \n","    # compute the q value\n","    q_val = compute_q_vals(Q, state, action)\n","    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n","        target = compute_targets(Q, reward, next_state, done, discount_factor)\n","    \n","    # loss is measured from error between current and newly expected Q values\n","    loss = F.smooth_l1_loss(q_val, target)\n","\n","    # backpropagation of loss to Neural Network (PyTorch magic)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    return loss.item() "]},{"cell_type":"code","execution_count":18,"metadata":{"nbgrader":{"grade":true,"grade_id":"cell-b060b822eec4282f","locked":true,"points":2,"schema_version":1,"solution":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["0.47801777720451355\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\hoiho\\.conda\\envs\\rlcourse\\lib\\site-packages\\ipykernel_launcher.py:53: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n"]}],"source":["# You may want to test your functions individually, but after you do so lets see if the method train works.\n","batch_size = 64\n","discount_factor = 0.8\n","learn_rate = 1e-3\n","# Simple gradient descent may take long, so we will use Adam\n","optimizer = optim.Adam(Q_net.parameters(), learn_rate)\n","\n","# We need a larger memory, fill with dummy data\n","transition = memory.sample(1)[0]\n","memory = ReplayMemory(10 * batch_size)\n","for i in range(batch_size):\n","    memory.push(transition)\n","\n","# Now let's see if it works\n","loss = train(Q_net, memory, optimizer, batch_size, discount_factor)\n","\n","print(loss)"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-3eafd0ab49103f3b","locked":true,"schema_version":1,"solution":false}},"source":["### 2.5 Put it all together"]},{"cell_type":"markdown","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-36b8a04b393d8104","locked":true,"schema_version":1,"solution":false}},"source":["Now that you have implemented the training step, you should be able to put everything together. Implement the function `run_episodes` that runs a number of episodes of DQN training. It should return the durations (e.g. number of steps) of each episode. Note: we pass the train function as an argument such that we can swap it for a different training step later."]},{"cell_type":"code","execution_count":19,"metadata":{"nbgrader":{"grade":false,"grade_id":"cell-540a7d50ecc1d046","locked":false,"schema_version":1,"solution":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to dqn_autograde.py\n"]}],"source":["%%execwritefile -a dqn_autograde.py\n","\n","def run_episodes(train, Q, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate):\n","    \n","    optimizer = optim.Adam(Q.parameters(), learn_rate)\n","    \n","    global_steps = 0  # Count the steps (do not reset at episode start, to compute epsilon)\n","    episode_durations = []  \n","    for i in range(num_episodes):\n","        s = env.reset()\n","        \n","        steps = 0\n","        while True:\n","            a = policy.sample_action(s)\n","            # Store this transition in memory:\n","            s_prime, r, done, _ = env.step(a)\n","            memory.push((s, a, r, s_prime, done))\n","            s = s_prime\n","            \n","            loss = train(Q, memory, optimizer, batch_size, discount_factor)\n","            \n","            steps += 1\n","            global_steps += 1\n","            # Update epsilon\n","            policy.set_epsilon(get_epsilon(global_steps))\n","            \n","            if done:\n","                if i % 10 == 0:\n","                    print(\"{2} Episode {0} finished after {1} steps\"\n","                          .format(i, steps, '\\033[92m' if steps >= 195 else '\\033[99m'))\n","                    print(\"epsilon: \", policy.epsilon)\n","                episode_durations.append(steps)\n","                #plot_durations()\n","                break\n","\n","    return episode_durations"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[99m Episode 0 finished after 21 steps\n","epsilon:  0.98005\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[99m Episode 10 finished after 11 steps\n","epsilon:  0.82615\n","\u001b[99m Episode 20 finished after 10 steps\n","epsilon:  0.677\n","\u001b[99m Episode 30 finished after 35 steps\n","epsilon:  0.4347500000000001\n","\u001b[99m Episode 40 finished after 31 steps\n","epsilon:  0.06805000000000005\n","\u001b[99m Episode 50 finished after 47 steps\n","epsilon:  0.05\n","\u001b[99m Episode 60 finished after 81 steps\n","epsilon:  0.05\n","\u001b[99m Episode 70 finished after 122 steps\n","epsilon:  0.05\n","\u001b[99m Episode 80 finished after 134 steps\n","epsilon:  0.05\n","\u001b[99m Episode 90 finished after 148 steps\n","epsilon:  0.05\n"]}],"source":["# Let's run it!\n","num_episodes = 100\n","batch_size = 64\n","discount_factor = 0.8\n","learn_rate = 1e-3\n","memory = ReplayMemory(10000)\n","num_hidden = 128\n","seed = 42  # This is not randomly chosen\n","\n","# We will seed the algorithm (before initializing QNetwork!) for reproducibility\n","random.seed(seed)\n","torch.manual_seed(seed)\n","env.seed(seed)\n","\n","Q_net = QNetwork(num_hidden)\n","policy = EpsilonGreedyPolicy(Q_net, 0.05)\n","episode_durations = run_episodes(train, Q_net, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate)"]},{"cell_type":"code","execution_count":21,"metadata":{"nbgrader":{"grade":true,"grade_id":"cell-928ecc11ed5c43d8","locked":true,"points":2,"schema_version":1,"solution":false}},"outputs":[{"data":{"text/plain":["Text(0.5, 1.0, 'Episode durations per episode')"]},"execution_count":21,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# And see the results\n","def smooth(x, N):\n","    cumsum = np.cumsum(np.insert(x, 0, 0)) \n","    return (cumsum[N:] - cumsum[:-N]) / float(N)\n","\n","plt.plot(smooth(episode_durations, 10))\n","plt.title('Episode durations per episode')"]},{"cell_type":"markdown","metadata":{},"source":["If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"]}],"metadata":{"celltoolbar":"Create Assignment","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":2}
>>>>>>> 991d99720f8706e763851a1eff69d0c6ab6ad23c
